### AI Red Teaming a.k.a. Awesome-LLM-Red-Teaming
#### _[<img src="images/back_button_2.png" width="25" height="25">Back to TOC](https://github.com/xsankar/Awesome-Awesome-LLM)_
| [About Me](https://ksankar.medium.com/about-me-the-pitter-patter-of-small-feats-de22f4c36ea6) | [Blog](https://ksankar.medium.com) |
| :- | :- |
> All things specific to Generative AI LLM Red Teaming 
> My Blog "What the heck is AI Red Teaming" https://bit.ly/ai-red-teaming
>
> |  |
> | :- |
> |***As of 11.30.23, I am working hard to build the repos - takes time to review and curate. Appreciate your patience ... Thanks ...***|
> |***As of  2.1.24, Started transcribing and curating the links from my Omnioutline to this GitHub page ...***|
> 
---
| [Best Practices](#best-practices) | [NIST](#nist) | [Survey & Analytical Paper Collection](#survey--analytical-papers) | [Metrics](#metrics) | [Benchmarks](#benchmarks) | [Datasets](#datasets) | [Other Repos](#other-repos) |
| :-: | :-: | :-: | :-: | :-: | :-: | :-: |
---
### Best Practices
[<img src="images/back_button_2.png" width="25" height="25">Top](#back-to-toc)
| Year | Title | Notes | 
| -: | :- | :- |
| 2023.07 | [Google's AI Red Team: the ethical hackers making AI safer](https://blog.google/technology/safety-security/googles-ai-red-team-the-ethical-hackers-making-ai-safer/) | Good Conceptual Diagrams|
| 2023.10 | [Best Practices for Securing LLM-Enabled Applications](https://developer.nvidia.com/blog/best-practices-for-securing-llm-enabled-applications/) | Nvidia |
| 2023.06 | [NVIDIA AI Red Team: An Introduction](https://developer.nvidia.com/blog/nvidia-ai-red-team-an-introduction/) | |
| | Sensational Press | |
| 2023.08 | [Hackers red-teaming A.I. are ‘breaking stuff left and right,’ but don’t expect quick fixes from DefCon: ‘There are no good guardrails](https://fortune.com/2023/08/13/hackers-red-teaming-ai-defcon-breaking-stuff-but-no-quick-fixes/) | | 
---
### NIST
[<img src="images/back_button_2.png" width="25" height="25">Top](#back-to-toc)
> All NIST documents, ideas, responses et al
> 
> Most probably will split into a Awesome-NIST repository. I have - see [Awesome-NIST](https://github.com/xsankar/Awesome-NIST/) 
---
### Survey & Analytical Papers
[<img src="images/back_button_2.png" width="25" height="25">Top](#back-to-toc)
| Year | Title | Notes | 
| -: | :- | :- |
| | Survey Papers | |
| 2024.01 | [Gradient-Based Language Model Red Teaming](https://export.arxiv.org/abs/2401.16656) | Hot from the press (at least for now! as of Stardate -299100.57) <br> <ul><li>I had written, in my Red Teaming blog, _“Tests follow a progressive nature, where a response could lead to another prompt deeper in the knowledge graph on the same topic”_ [Here](https://bit.ly/ai-red-teaming)</li><li>I was thinking of a prompt hierarchy, this paper does the adaptive Red Teaming by creating new, modified prompts using backprop !!</li></ul> |
| 2024.01 | [Red Teaming Visual Language Models](https://arxiv.org/abs/2401.12915) | |
| 2024.01 | [Red-Teaming for Generative AI: Silver Bullet or Security Theater?](https://arxiv.org/abs/2401.15897) | |
| 2023.11 | [Summon a Demon and Bind it: A Grounded Theory of LLM Red Teaming in the Wild](https://arxiv.org/abs/2311.06237) | |
| 2023.08 | [Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment](https://arxiv.org/abs/2308.09662) | |
| 2023.06 | [Explore, Establish, Exploit: Red Teaming Language Models from Scratch](https://arxiv.org/abs/2306.09442) | |
| 2022.09 | [Red Teaming Language Models to Reduce Harms: Methods, Scaling Behaviors, and Lessons Learned](https://arxiv.org/abs/2209.07858) | |
| | LLMs vs. LLMs | |
| 2022.02 | [Red Teaming Language Models with Language Models](https://arxiv.org/abs/2202.03286) | |
| | Analytical Papers | |
| 2023.10 | [Risk Assessment and Statistical Significance in the Age of Foundation Models](https://arxiv.org/abs/2310.07132) | |
---
### Metrics
[<img src="images/back_button_2.png" width="25" height="25">Top](#back-to-toc)

LLM benchmarks (See [LLM Evaluation Topics for a quick intro](https://github.com/xsankar/Awesome-LLM-Eval-MetricMinds?tab=readme-ov-file#metrics--benchmarks-by-topic))
> I will start polulating this section
---
### Benchmarks
[<img src="images/back_button_2.png" width="25" height="25">Top](#back-to-toc)

LLM benchmarks (See [LLM Evaluation Topics for a quick intro](https://github.com/xsankar/Awesome-LLM-Eval-MetricMinds?tab=readme-ov-file#metrics--benchmarks-by-topic))
> I will start polulating this section
---
### Datasets
[<img src="images/back_button_2.png" width="25" height="25">Top](#back-to-toc)

LLM benchmarks (See [LLM Evaluation Topics for a quick intro](https://github.com/xsankar/Awesome-LLM-Eval-MetricMinds?tab=readme-ov-file#metrics--benchmarks-by-topic))
> I will start polulating this section
---
### Other Repos
[<img src="images/back_button_2.png" width="25" height="25">Top](#back-to-toc)

LLM benchmarks (See [LLM Evaluation Other Repos](https://github.com/xsankar/Awesome-LLM-Eval-MetricMinds?tab=readme-ov-file#other-repos)
> I will start polulating this section
> 
| Title | Notes |
| :- | :- |
| [Awesome Security](https://github.com/sbilly/awesome-security) | |
| [Awesome Controls](https://github.com/trevorbryant/awesome-controls)| Links to various security fraeworks. Last update 4 years ago, still useful |
| [Awesome Infosec](https://github.com/onlurking/awesome-infosec) | A curated list of awesome information security resources |
---
